{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 is not trainable\n",
      "block1_conv1 is not trainable\n",
      "block1_conv2 is not trainable\n",
      "block1_pool is not trainable\n",
      "block2_conv1 is not trainable\n",
      "block2_conv2 is not trainable\n",
      "block2_pool is not trainable\n",
      "block3_conv1 is not trainable\n",
      "block3_conv2 is not trainable\n",
      "block3_conv3 is not trainable\n",
      "block3_pool is not trainable\n",
      "block4_conv1 is not trainable\n",
      "block4_conv2 is not trainable\n",
      "block4_conv3 is not trainable\n",
      "block4_pool is not trainable\n",
      "block5_conv1 is not trainable\n",
      "block5_conv2 is not trainable\n",
      "block5_conv3 is trainable\n",
      "block5_pool is trainable\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 263,169\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def vgg16_model(trainable=True):\n",
    "    base_model = VGG16(False, \"imagenet\")\n",
    "    train_from_layer = -2\n",
    "    for layer in base_model.layers[:train_from_layer]:\n",
    "        layer.trainable = False\n",
    "        print(\"{} is not trainable\".format(layer.name))\n",
    "    for layer in base_model.layers[train_from_layer:]:\n",
    "        #layer.trainable = True\n",
    "        layer.trainable = False\n",
    "        print(\"{} is trainable\".format(layer.name))\n",
    "    last_conv_layer = base_model.get_layer(\"block5_conv3\")\n",
    "    x = GlobalAveragePooling2D()(last_conv_layer.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)        \n",
    "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(base_model.input, predictions)\n",
    "\n",
    "\n",
    "\n",
    "model = vgg16_model(False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets import Datasets\n",
    "\n",
    "dataset_name = \"Bradbury\"\n",
    "dataset = Datasets.datasets()[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Add preprocessing\n",
    "train_images = dataset[0].images\n",
    "train_labels  = dataset[0].labels\n",
    "\n",
    "test_images = dataset[1].images\n",
    "test_labels = dataset[1].labels\n",
    "\n",
    "validation_images = dataset[2].images\n",
    "validation_labels = dataset[2].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ProjectPaths import ProjectPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range = [0.9, 1.2],\n",
    "    #brightness_range = [0.5, 1.5],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator = data_generator.flow(train_images, train_labels, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(test_images, test_labels, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def schedule_lr(epoch):\n",
    "    return 0.01\n",
    "\n",
    "lrCallback = LearningRateScheduler(schedule_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PerformanceMetrics import PerformanceMetrics\n",
    "\n",
    "model.compile(optimizer=\"adadelta\", loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', PerformanceMetrics.precision,\n",
    "                           PerformanceMetrics.recall, PerformanceMetrics.fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.5298 - acc: 0.7354 - precision: 0.7362 - recall: 0.7683 - fmeasure: 0.7304 - val_loss: 0.4424 - val_acc: 0.8334 - val_precision: 0.7609 - val_recall: 0.9652 - val_fmeasure: 0.8492\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83338, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__01_0.83.hdf5\n",
      "Epoch 2/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4508 - acc: 0.7909 - precision: 0.7645 - recall: 0.8468 - fmeasure: 0.7990 - val_loss: 0.4143 - val_acc: 0.8339 - val_precision: 0.7556 - val_recall: 0.9808 - val_fmeasure: 0.8518\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83338 to 0.83388, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__02_0.83.hdf5\n",
      "Epoch 3/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4365 - acc: 0.7990 - precision: 0.7700 - recall: 0.8576 - fmeasure: 0.8073 - val_loss: 0.3657 - val_acc: 0.8500 - val_precision: 0.8179 - val_recall: 0.8971 - val_fmeasure: 0.8534\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83388 to 0.84999, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__03_0.85.hdf5\n",
      "Epoch 4/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4265 - acc: 0.8048 - precision: 0.7742 - recall: 0.8646 - fmeasure: 0.8133 - val_loss: 0.3612 - val_acc: 0.8525 - val_precision: 0.8002 - val_recall: 0.9361 - val_fmeasure: 0.8606\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84999 to 0.85250, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__04_0.85.hdf5\n",
      "Epoch 5/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4204 - acc: 0.8070 - precision: 0.7763 - recall: 0.8653 - fmeasure: 0.8150 - val_loss: 0.3689 - val_acc: 0.8540 - val_precision: 0.7976 - val_recall: 0.9440 - val_fmeasure: 0.8627\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85250 to 0.85401, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__05_0.85.hdf5\n",
      "Epoch 6/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.4143 - acc: 0.8110 - precision: 0.7765 - recall: 0.8729 - fmeasure: 0.8193 - val_loss: 0.4241 - val_acc: 0.8120 - val_precision: 0.7267 - val_recall: 0.9913 - val_fmeasure: 0.8367\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.85401\n",
      "Epoch 7/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4106 - acc: 0.8134 - precision: 0.7819 - recall: 0.8727 - fmeasure: 0.8216 - val_loss: 0.3691 - val_acc: 0.8515 - val_precision: 0.7878 - val_recall: 0.9580 - val_fmeasure: 0.8625\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85401\n",
      "Epoch 8/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4088 - acc: 0.8129 - precision: 0.7808 - recall: 0.8723 - fmeasure: 0.8210 - val_loss: 0.3499 - val_acc: 0.8555 - val_precision: 0.8143 - val_recall: 0.9184 - val_fmeasure: 0.8611\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.85401 to 0.85552, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__08_0.86.hdf5\n",
      "Epoch 9/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4078 - acc: 0.8131 - precision: 0.7797 - recall: 0.8737 - fmeasure: 0.8211 - val_loss: 0.3636 - val_acc: 0.8510 - val_precision: 0.7918 - val_recall: 0.9491 - val_fmeasure: 0.8612\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85552\n",
      "Epoch 10/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4045 - acc: 0.8135 - precision: 0.7814 - recall: 0.8738 - fmeasure: 0.8219 - val_loss: 0.3578 - val_acc: 0.8505 - val_precision: 0.7893 - val_recall: 0.9513 - val_fmeasure: 0.8608\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85552\n",
      "Epoch 11/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4031 - acc: 0.8169 - precision: 0.7836 - recall: 0.8762 - fmeasure: 0.8246 - val_loss: 0.3660 - val_acc: 0.8507 - val_precision: 0.7812 - val_recall: 0.9700 - val_fmeasure: 0.8635\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.85552\n",
      "Epoch 12/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.4050 - acc: 0.8128 - precision: 0.7811 - recall: 0.8709 - fmeasure: 0.8208 - val_loss: 0.3479 - val_acc: 0.8601 - val_precision: 0.8071 - val_recall: 0.9419 - val_fmeasure: 0.8674\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.85552 to 0.86006, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__12_0.86.hdf5\n",
      "Epoch 13/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3990 - acc: 0.8174 - precision: 0.7851 - recall: 0.8755 - fmeasure: 0.8252 - val_loss: 0.3541 - val_acc: 0.8507 - val_precision: 0.7822 - val_recall: 0.9679 - val_fmeasure: 0.8632\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.86006\n",
      "Epoch 14/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3964 - acc: 0.8191 - precision: 0.7861 - recall: 0.8786 - fmeasure: 0.8271 - val_loss: 0.3463 - val_acc: 0.8510 - val_precision: 0.7864 - val_recall: 0.9598 - val_fmeasure: 0.8624\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.86006\n",
      "Epoch 15/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3952 - acc: 0.8220 - precision: 0.7893 - recall: 0.8795 - fmeasure: 0.8291 - val_loss: 0.3423 - val_acc: 0.8563 - val_precision: 0.7992 - val_recall: 0.9470 - val_fmeasure: 0.8648\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86006\n",
      "Epoch 16/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3951 - acc: 0.8204 - precision: 0.7895 - recall: 0.8751 - fmeasure: 0.8273 - val_loss: 0.3640 - val_acc: 0.8505 - val_precision: 0.7764 - val_recall: 0.9796 - val_fmeasure: 0.8642\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.86006\n",
      "Epoch 17/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3970 - acc: 0.8193 - precision: 0.7882 - recall: 0.8749 - fmeasure: 0.8266 - val_loss: 0.3590 - val_acc: 0.8507 - val_precision: 0.7792 - val_recall: 0.9746 - val_fmeasure: 0.8640\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.86006\n",
      "Epoch 18/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3926 - acc: 0.8222 - precision: 0.7910 - recall: 0.8779 - fmeasure: 0.8296 - val_loss: 0.3486 - val_acc: 0.8515 - val_precision: 0.7832 - val_recall: 0.9673 - val_fmeasure: 0.8636\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.86006\n",
      "Epoch 19/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3945 - acc: 0.8202 - precision: 0.7859 - recall: 0.8808 - fmeasure: 0.8278 - val_loss: 0.3618 - val_acc: 0.8482 - val_precision: 0.7747 - val_recall: 0.9774 - val_fmeasure: 0.8624\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.86006\n",
      "Epoch 20/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3855 - acc: 0.8247 - precision: 0.7921 - recall: 0.8815 - fmeasure: 0.8319 - val_loss: 0.3515 - val_acc: 0.8500 - val_precision: 0.7780 - val_recall: 0.9751 - val_fmeasure: 0.8635\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.86006\n",
      "Epoch 21/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3896 - acc: 0.8227 - precision: 0.7906 - recall: 0.8778 - fmeasure: 0.8296 - val_loss: 0.3510 - val_acc: 0.8510 - val_precision: 0.7802 - val_recall: 0.9730 - val_fmeasure: 0.8640\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.86006\n",
      "Epoch 22/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3877 - acc: 0.8217 - precision: 0.7885 - recall: 0.8794 - fmeasure: 0.8291 - val_loss: 0.3394 - val_acc: 0.8583 - val_precision: 0.7965 - val_recall: 0.9588 - val_fmeasure: 0.8681\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.86006\n",
      "Epoch 23/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3906 - acc: 0.8231 - precision: 0.7907 - recall: 0.8796 - fmeasure: 0.8303 - val_loss: 0.3458 - val_acc: 0.8528 - val_precision: 0.7859 - val_recall: 0.9645 - val_fmeasure: 0.8642\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.86006\n",
      "Epoch 24/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3858 - acc: 0.8248 - precision: 0.7919 - recall: 0.8818 - fmeasure: 0.8322 - val_loss: 0.3504 - val_acc: 0.8558 - val_precision: 0.7867 - val_recall: 0.9713 - val_fmeasure: 0.8674\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.86006\n",
      "Epoch 25/100\n",
      "496/496 [==============================] - 25s 49ms/step - loss: 0.3846 - acc: 0.8251 - precision: 0.7928 - recall: 0.8816 - fmeasure: 0.8324 - val_loss: 0.3416 - val_acc: 0.8606 - val_precision: 0.7981 - val_recall: 0.9612 - val_fmeasure: 0.8702\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.86006 to 0.86056, saving model to /media/tim/Data/Work/CBS/DeepSolaris/Models/vgg16_3t_wmp_wr_Bradbury_2018-12-05_64_100/vgg16_3t_wmp_wr_Bradbury__25_0.86.hdf5\n",
      "Epoch 26/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3882 - acc: 0.8228 - precision: 0.7917 - recall: 0.8768 - fmeasure: 0.8294 - val_loss: 0.3396 - val_acc: 0.8603 - val_precision: 0.7982 - val_recall: 0.9607 - val_fmeasure: 0.8699\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.86056\n",
      "Epoch 27/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3825 - acc: 0.8268 - precision: 0.7960 - recall: 0.8812 - fmeasure: 0.8342 - val_loss: 0.3450 - val_acc: 0.8530 - val_precision: 0.7828 - val_recall: 0.9722 - val_fmeasure: 0.8654\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.86056\n",
      "Epoch 28/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3797 - acc: 0.8294 - precision: 0.7971 - recall: 0.8835 - fmeasure: 0.8355 - val_loss: 0.3448 - val_acc: 0.8578 - val_precision: 0.7942 - val_recall: 0.9617 - val_fmeasure: 0.8680\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.86056\n",
      "Epoch 29/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3817 - acc: 0.8269 - precision: 0.7949 - recall: 0.8825 - fmeasure: 0.8339 - val_loss: 0.3384 - val_acc: 0.8558 - val_precision: 0.7911 - val_recall: 0.9622 - val_fmeasure: 0.8664\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.86056\n",
      "Epoch 30/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3867 - acc: 0.8251 - precision: 0.7930 - recall: 0.8814 - fmeasure: 0.8326 - val_loss: 0.3686 - val_acc: 0.8419 - val_precision: 0.7625 - val_recall: 0.9869 - val_fmeasure: 0.8584\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.86056\n",
      "Epoch 31/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3793 - acc: 0.8284 - precision: 0.7969 - recall: 0.8842 - fmeasure: 0.8358 - val_loss: 0.3434 - val_acc: 0.8553 - val_precision: 0.7879 - val_recall: 0.9683 - val_fmeasure: 0.8668\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.86056\n",
      "Epoch 32/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3843 - acc: 0.8269 - precision: 0.7942 - recall: 0.8832 - fmeasure: 0.8341 - val_loss: 0.3418 - val_acc: 0.8543 - val_precision: 0.7834 - val_recall: 0.9750 - val_fmeasure: 0.8668\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.86056\n",
      "Epoch 33/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3801 - acc: 0.8287 - precision: 0.7972 - recall: 0.8821 - fmeasure: 0.8352 - val_loss: 0.3425 - val_acc: 0.8545 - val_precision: 0.7870 - val_recall: 0.9673 - val_fmeasure: 0.8660\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.86056\n",
      "Epoch 34/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3817 - acc: 0.8266 - precision: 0.7957 - recall: 0.8802 - fmeasure: 0.8334 - val_loss: 0.3695 - val_acc: 0.8424 - val_precision: 0.7634 - val_recall: 0.9864 - val_fmeasure: 0.8587\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.86056\n",
      "Epoch 35/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3812 - acc: 0.8270 - precision: 0.7949 - recall: 0.8815 - fmeasure: 0.8336 - val_loss: 0.3546 - val_acc: 0.8512 - val_precision: 0.7792 - val_recall: 0.9754 - val_fmeasure: 0.8644\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.86056\n",
      "Epoch 36/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3807 - acc: 0.8262 - precision: 0.7948 - recall: 0.8813 - fmeasure: 0.8337 - val_loss: 0.3396 - val_acc: 0.8563 - val_precision: 0.7887 - val_recall: 0.9689 - val_fmeasure: 0.8676\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.86056\n",
      "Epoch 37/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3750 - acc: 0.8321 - precision: 0.8027 - recall: 0.8805 - fmeasure: 0.8376 - val_loss: 0.3620 - val_acc: 0.8439 - val_precision: 0.7644 - val_recall: 0.9879 - val_fmeasure: 0.8600\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.86056\n",
      "Epoch 38/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3816 - acc: 0.8264 - precision: 0.7948 - recall: 0.8806 - fmeasure: 0.8333 - val_loss: 0.3373 - val_acc: 0.8530 - val_precision: 0.7818 - val_recall: 0.9744 - val_fmeasure: 0.8657\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.86056\n",
      "Epoch 39/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3814 - acc: 0.8274 - precision: 0.7945 - recall: 0.8832 - fmeasure: 0.8340 - val_loss: 0.3557 - val_acc: 0.8505 - val_precision: 0.7738 - val_recall: 0.9854 - val_fmeasure: 0.8649\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.86056\n",
      "Epoch 40/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3772 - acc: 0.8300 - precision: 0.7995 - recall: 0.8839 - fmeasure: 0.8372 - val_loss: 0.3515 - val_acc: 0.8528 - val_precision: 0.7772 - val_recall: 0.9838 - val_fmeasure: 0.8666\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.86056\n",
      "Epoch 41/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3745 - acc: 0.8307 - precision: 0.7988 - recall: 0.8839 - fmeasure: 0.8368 - val_loss: 0.3532 - val_acc: 0.8510 - val_precision: 0.7762 - val_recall: 0.9816 - val_fmeasure: 0.8649\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.86056\n",
      "Epoch 42/100\n",
      "496/496 [==============================] - 25s 49ms/step - loss: 0.3780 - acc: 0.8283 - precision: 0.7984 - recall: 0.8811 - fmeasure: 0.8355 - val_loss: 0.3602 - val_acc: 0.8462 - val_precision: 0.7693 - val_recall: 0.9834 - val_fmeasure: 0.8614\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.86056\n",
      "Epoch 43/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3760 - acc: 0.8286 - precision: 0.7986 - recall: 0.8803 - fmeasure: 0.8349 - val_loss: 0.3448 - val_acc: 0.8570 - val_precision: 0.7886 - val_recall: 0.9718 - val_fmeasure: 0.8688\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.86056\n",
      "Epoch 44/100\n",
      "496/496 [==============================] - 25s 51ms/step - loss: 0.3754 - acc: 0.8311 - precision: 0.8002 - recall: 0.8819 - fmeasure: 0.8368 - val_loss: 0.3503 - val_acc: 0.8512 - val_precision: 0.7781 - val_recall: 0.9778 - val_fmeasure: 0.8647\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.86056\n",
      "Epoch 45/100\n",
      "496/496 [==============================] - 25s 50ms/step - loss: 0.3767 - acc: 0.8293 - precision: 0.7968 - recall: 0.8838 - fmeasure: 0.8358 - val_loss: 0.3702 - val_acc: 0.8379 - val_precision: 0.7573 - val_recall: 0.9880 - val_fmeasure: 0.8555\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.86056\n",
      "Epoch 46/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3746 - acc: 0.8313 - precision: 0.8012 - recall: 0.8820 - fmeasure: 0.8374 - val_loss: 0.3437 - val_acc: 0.8540 - val_precision: 0.7829 - val_recall: 0.9747 - val_fmeasure: 0.8666\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86056\n",
      "Epoch 47/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3765 - acc: 0.8295 - precision: 0.7968 - recall: 0.8848 - fmeasure: 0.8363 - val_loss: 0.3560 - val_acc: 0.8455 - val_precision: 0.7674 - val_recall: 0.9858 - val_fmeasure: 0.8611\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86056\n",
      "Epoch 48/100\n",
      "496/496 [==============================] - 24s 49ms/step - loss: 0.3766 - acc: 0.8310 - precision: 0.7976 - recall: 0.8864 - fmeasure: 0.8375 - val_loss: 0.3503 - val_acc: 0.8510 - val_precision: 0.7756 - val_recall: 0.9830 - val_fmeasure: 0.8652\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e381e0240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"vgg16_3t_wmp_wr_{}\".format(dataset_name)\n",
    "\n",
    "checkpoint_dir = ProjectPaths.instance().checkpoint_dir_for(model_name, batch_size, epochs)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "file_in_checkpoint_dir = ProjectPaths.instance().file_in_checkpoint_dir(model_name, batch_size,\n",
    "                                                                 epochs,  model_name +\n",
    "                                                                 \"__{epoch:02d}_{val_acc:.2f}.hdf5\")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(patience=10)\n",
    "model_checkpoint_callback = ModelCheckpoint(file_in_checkpoint_dir, monitor='val_acc', verbose=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True)\n",
    "\n",
    "log_dir = os.path.join(ProjectPaths.instance().log_dir, model_name)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0,  write_graph=False, write_images=False)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(train_labels) // batch_size, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[early_stopping_callback, model_checkpoint_callback, tensorboard_callback],\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31776/31776 [==============================] - 13s 399us/step\n",
      "3973/3973 [==============================] - 2s 403us/step\n",
      "3973/3973 [==============================] - 2s 400us/step\n",
      "       loss       acc  precision    recall  fmeasure\n",
      "0  0.349678  0.848439   0.778929  0.973567  0.863916\n",
      "1  0.350276  0.850994   0.775621  0.983001  0.865168\n",
      "2  0.367178  0.835892   0.766750  0.972160  0.855646\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_eval = model.evaluate(train_images, train_labels, batch_size)\n",
    "test_eval = model.evaluate(test_images, test_labels, batch_size)\n",
    "validation_eval = model.evaluate(validation_images, validation_labels, batch_size)\n",
    "\n",
    "np_model_evaluations = np.array([train_eval, test_eval, validation_eval])\n",
    "\n",
    "evaluations = pd.DataFrame(np_model_evaluations, columns=model.metrics_names)\n",
    "print(evaluations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def find_optimal_cutoff(target, predicted):\n",
    "   \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "   Parameters\n",
    "   ----------\n",
    "   target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "   predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "   Returns\n",
    "   -------\n",
    "   list type, with optimal cutoff value\n",
    "\n",
    "   \"\"\"\n",
    "   fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "   i = np.arange(len(tpr))\n",
    "   roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "   roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "   return list(roc_t['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_predictions = model.predict(test_images, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = find_optimal_cutoff(test_labels, test_predictions)\n",
    "cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = test_predictions > cut_off\n",
    "confusion_matrix(test_labels, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aachen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_dataset = Datasets.datasets()[\"AcMüDüHo\"]\n",
    "\n",
    "train_images = ac_dataset[0].images\n",
    "train_labels = ac_dataset[0].labels\n",
    "\n",
    "test_images = ac_dataset[1].images\n",
    "test_labels = ac_dataset[1].labels\n",
    "\n",
    "validation_images = ac_dataset[2].images\n",
    "validation_labels = ac_dataset[2].labels\n",
    "\n",
    "eval_images = np.concatenate((train_images, test_images, validation_images), axis=0)\n",
    "eval_labels = np.concatenate((train_labels, test_labels, validation_labels), axis=0)\n",
    "\n",
    "\n",
    "print(train_images.shape, test_images.shape, validation_images.shape)\n",
    "print(eval_images.shape, eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predictions = model.predict(eval_images, batch_size) > cut_off\n",
    "confusion_matrix(eval_labels, eval_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(eval_labels, eval_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresno_dataset = Datasets.datasets()[\"Fresno\"]\n",
    "\n",
    "train_images = fresno_dataset[0].images\n",
    "train_labels = fresno_dataset[0].labels\n",
    "\n",
    "test_images = fresno_dataset[1].images\n",
    "test_labels = fresno_dataset[1].labels\n",
    "\n",
    "validation_images = fresno_dataset[2].images\n",
    "validation_labels = fresno_dataset[2].labels\n",
    "\n",
    "fresno_eval_images = np.concatenate((train_images, test_images, validation_images), axis=0)\n",
    "fresno_eval_labels = np.concatenate((train_labels, test_labels, validation_labels), axis=0)\n",
    "\n",
    "\n",
    "print(train_images.shape, test_images.shape, validation_images.shape)\n",
    "print(fresno_eval_images.shape, fresno_eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresno_eval_predictions = model.predict(fresno_eval_images, batch_size) > cut_off\n",
    "confusion_matrix(fresno_eval_labels, fresno_eval_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(fresno_eval_labels, fresno_eval_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heerlen Preprocessing\n",
    "\n",
    "Now we use the trained model to preprocess the images from Heerlen and see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heerlen_dir = os.path.join(ProjectPaths.instance().image_dir, \"Heerlen75x75\")\n",
    "image_files = [os.path.join(heerlen_dir, filename) for filename in os.listdir(heerlen_dir) if filename.endswith(\"rgb_2016.tiff\") or filename.endswith(\"rgb_2017.tiff\")]\n",
    "image_files = sorted(image_files)\n",
    "image_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dir = os.path.join(ProjectPaths.instance().image_dir, \"Heerlen75x75_preprocessed\")\n",
    "positives_dir = os.path.join(preprocessed_dir, \"Positives\")\n",
    "negatives_dir = os.path.join(preprocessed_dir, \"Negatives\")\n",
    "\n",
    "create_dir(positives_dir)\n",
    "create_dir(negatives_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def prepare_image(filename):\n",
    "    img = load_img(filename) \n",
    "    img_array = img_to_array(img)\n",
    "    return img_array[:,:, ::-1]\n",
    "\n",
    "def image_generator(image_files, batch_size):\n",
    "    batch = []\n",
    "    for i, filename in enumerate(image_files):\n",
    "        if i > 0 and (i % batch_size == 0):\n",
    "            old_batch = batch\n",
    "            batch = []\n",
    "            yield np.array(old_batch)\n",
    "        batch.append(prepare_image(filename))\n",
    "    #if len(batch) > 0:\n",
    "    #    repeat_last = len(batch) - batch_size\n",
    "    #    repeated_images = [batch[-1] for i in range(repeat_last)]\n",
    "    #   yield np.array(batch + repeated_images)\n",
    "\n",
    "heerlen_image_generator = image_generator(image_files, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels for the images in the source directory and write them to positive or negative directory based on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(heerlen_image_generator, steps=len(image_files) // batch_size)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(predictions.shape[0])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "for i, file_path in enumerate(image_files):        \n",
    "    filename = os.path.basename(file_path)\n",
    "    if i >= predictions.shape[0]:\n",
    "        break\n",
    "    \n",
    "    prediction = predictions[i]    \n",
    "    if prediction > cut_off:\n",
    "        output_path = os.path.join(positives_dir, filename)\n",
    "    else:        \n",
    "        output_path = os.path.join(negatives_dir, filename)\n",
    "    copyfile(file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(positives_dir)), len(os.listdir(negatives_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [load_img(os.path.join(positives_dir, image)) for i, image in enumerate(os.listdir(positives_dir)) if i < 25]\n",
    "\n",
    "_, ax = plt.subplots(5,5, figsize=(10,10))\n",
    "\n",
    "j = 0\n",
    "for r in range(5):\n",
    "    for c in range(5):\n",
    "        ax[r,c].imshow(positive_images[j])     \n",
    "        j += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images = [load_img(os.path.join(negatives_dir, image)) for i, image in enumerate(os.listdir(negatives_dir)) if i < 25]\n",
    "\n",
    "_, ax = plt.subplots(5,5, figsize=(10,10))\n",
    "\n",
    "j = 0\n",
    "for r in range(5):\n",
    "    for c in range(5):\n",
    "        ax[r,c].imshow(negative_images[j])     \n",
    "        j += 1 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
