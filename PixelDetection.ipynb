{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* normaliseren per dataset (z-score vs 0-1)\n",
    "* normaliseren per plaatje (z-score vs 0-1)\n",
    "* converteren naar grijswaarden plaatje\n",
    "* histogram test-set converteren naar histogram training set\n",
    "* gabor filter\n",
    "* normaliseren per cluster\n",
    "* T-SNE met feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProjectPaths import ProjectPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_image_masks.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_images.npy\"))\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_image(image):\n",
    "    avg_kernel = np.ones((3,3), dtype=np.float32)\n",
    "    avg_kernel /= 9\n",
    "    return cv.filter2D(image, -1, avg_kernel).reshape(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_image(images[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_locations(r = 2, n_channels = 3):\n",
    "    x = [-r, 0, r]\n",
    "    y = [-r, 0, r]\n",
    "    mask = np.zeros((1+2*r,1+2*r))\n",
    "    \n",
    "    for xc in x:\n",
    "        for yc in y:\n",
    "            mask[r + yc, r + xc] = 1.0\n",
    "    return np.tile(mask,(n_channels,1,1)).T\n",
    "    \n",
    "window_mask = window_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_channels(image):\n",
    "    if image.ndim == 3:\n",
    "        return image.shape[2]\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image, r=2):\n",
    "    #grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    \n",
    "    kernel = window_locations(r, number_of_channels(image))\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "\n",
    "    # allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv.copyMakeBorder(image, pad, pad, pad, pad, cv.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW, 9 *  number_of_channels(image)), dtype=\"float32\")\n",
    "    # loop over the input image, \"sliding\" the kernel across\n",
    "    # each (x, y)-coordinate from left-to-right and top to\n",
    "    # bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates\n",
    "            # dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\n",
    "            # perform the actual selection by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel\n",
    "            k = (roi * kernel)\n",
    "\n",
    "            # store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad, :] = k[np.nonzero(kernel)]\n",
    "    \n",
    "    # return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def std_image(image):\n",
    "    average = avg_image(image)\n",
    "    x2_min_avg = (image - average) * (image - average);\n",
    "    avg_kernel_3d = np.ones((3, 3, number_of_channels(image)), dtype=np.float32)\n",
    "    avg_kernel_3d /= 9\n",
    "    conv_image = ndimage.convolve(x2_min_avg, avg_kernel_3d, np.float32) \n",
    "    return np.sqrt(conv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return (image - image.min(axis=(0,1))) / (image.max(axis=(0,1)) - image.min(axis=(0,1)))\n",
    "#def normalize_image(image):\n",
    "#    return (image - image.min()) / (image.max() - image.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_std = images[0]\n",
    "std = std_image(im_std)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "std.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image):\n",
    "    avg = avg_image(image)\n",
    "    std = std_image(image)\n",
    "    \n",
    "    avg_output2 = extract_features(avg)\n",
    "    std_output2 = extract_features(std)\n",
    "    \n",
    "    avg_output4 = extract_features(avg, 4)\n",
    "    std_output4 = extract_features(std, 4)\n",
    "    return np.concatenate((avg_output2, std_output2, avg_output4, std_output4), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for(images):\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        feature_list.append(get_features(image))\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 108)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_features_for(images)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000, 108)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_features = X.reshape(120*75*75, 108)\n",
    "pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_masks = mask_images.reshape(120*75*75)\n",
    "pixel_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/.virtualenvs/cv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0130331 , 0.00790096, 0.00954888, 0.01579249, 0.00465025,\n",
       "       0.03333219, 0.00746109, 0.02054315, 0.03206518, 0.01076767,\n",
       "       0.00296814, 0.01371   , 0.05860174, 0.00740536, 0.01352252,\n",
       "       0.05287387, 0.00339236, 0.03352498, 0.0111402 , 0.00464456,\n",
       "       0.00518657, 0.03179826, 0.00361366, 0.00758616, 0.02775775,\n",
       "       0.00318132, 0.00905092, 0.00262694, 0.00347946, 0.00239997,\n",
       "       0.00362136, 0.00385288, 0.00260554, 0.00430143, 0.00680386,\n",
       "       0.00348123, 0.00275953, 0.00287193, 0.00356526, 0.00265178,\n",
       "       0.00390683, 0.0042736 , 0.00335392, 0.00247733, 0.00417426,\n",
       "       0.00195899, 0.00237348, 0.0023229 , 0.00226336, 0.00331601,\n",
       "       0.00326879, 0.00450432, 0.0040863 , 0.0021054 , 0.01113706,\n",
       "       0.00483999, 0.02513629, 0.00656336, 0.0177308 , 0.02818839,\n",
       "       0.0193414 , 0.00629413, 0.04194013, 0.02756647, 0.00316216,\n",
       "       0.00443361, 0.04250644, 0.01758213, 0.0103157 , 0.02413087,\n",
       "       0.00653913, 0.00783198, 0.00541845, 0.00268107, 0.00472169,\n",
       "       0.00452541, 0.00398921, 0.00507817, 0.00684884, 0.01558727,\n",
       "       0.00485145, 0.0026856 , 0.00305868, 0.00279763, 0.00353711,\n",
       "       0.0031008 , 0.00242875, 0.00350174, 0.00760376, 0.00722473,\n",
       "       0.00282268, 0.00524032, 0.00292018, 0.00233615, 0.00304162,\n",
       "       0.00301685, 0.00319054, 0.00369079, 0.00503897, 0.00560025,\n",
       "       0.00682297, 0.00396765, 0.00309866, 0.00399713, 0.00385698,\n",
       "       0.00268615, 0.00289581, 0.00643597])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def predict(clf, X_test, y_test):\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"accuracy={}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     91682\n",
      "         255       0.96      0.94      0.95     43318\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    135000\n",
      "   macro avg       0.97      0.96      0.96    135000\n",
      "weighted avg       0.97      0.97      0.97    135000\n",
      "\n",
      "accuracy=0.9673111111111111\n",
      "[[90023  1659]\n",
      " [ 2754 40564]]\n"
     ]
    }
   ],
   "source": [
    "predict(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features = get_features_for([images[-1]])\n",
    "im_features = im_features.reshape(75*75, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pred = clf.predict(im_features)\n",
    "im_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image = im_pred.reshape(75, 75)\n",
    "plt.imshow(prediction_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[-1][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProjectPaths import ProjectPaths\n",
    "from Datasets import Datasets\n",
    "\n",
    "\n",
    "ProjectPaths.instance()\n",
    "ac_dataset = Datasets.datasets()[\"AcMüDüHo\"]\n",
    "train = ac_dataset[0].images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[8][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features2 = get_features_for([train[8]])\n",
    "im_features2 = im_features2.reshape(75*75, 108)\n",
    "\n",
    "im_pred = clf.predict(im_features2)\n",
    "prediction_image = im_pred.reshape(75, 75)\n",
    "\n",
    "plt.imshow(prediction_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[8][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features3 = get_features_for([train[8]])\n",
    "im_features3 = im_features3.reshape(75*75, 108)\n",
    "\n",
    "im_pred = clf.predict(im_features3)\n",
    "prediction_image = im_pred.reshape(75, 75)\n",
    "\n",
    "plt.imshow(normalize_image(prediction_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def reorderMatrix(u):\n",
    "    c1 = np.array([1/3 * math.sqrt(3) for _ in range(3)])\n",
    "    c2 = np.array([1, -1, -1] * c1)\n",
    "    c3 = np.array([0, -1/2 * math.sqrt(2), 1/2 * math.sqrt(2)])\n",
    "    v1 = u.dot(c2)\n",
    "    i1 = np.argmax(v1)\n",
    "    v2 = u.dot(c3)\n",
    "    i2 = np.argmax(v2)\n",
    "    if i1 == 2 and i2 == 1:\n",
    "        temp = u[i1]\n",
    "        u[i1] =  u[i2]\n",
    "        u[i2] = temp\n",
    "    return u\n",
    "\n",
    "def flattenImage(rgbImage):\n",
    "    return rgbImage.reshape(rgbImage.shape[0] * rgbImage.shape[1], 3)\n",
    "\n",
    "def imageMean(image):\n",
    "    return (1 / image.size) * np.sum(image)\n",
    "\n",
    "def centerImage(image):\n",
    "    return image - imageMean(image)\n",
    "\n",
    "def imageCovariance(image1, image2):\n",
    "    return (1 / image1.size) * np.dot(centerImage(image1).ravel(), centerImage(image2).ravel())\n",
    "\n",
    "def rgbImageCovarianceMatrix(rgbImage):\n",
    "    covarianceMatrix = np.zeros([3,3])\n",
    "    for r in range(3):\n",
    "        for c in range (3):\n",
    "            covariance = imageCovariance(rgbImage[:,:,r], rgbImage[:,:,c])\n",
    "            covarianceMatrix[r, c] = covariance\n",
    "            covarianceMatrix[c, r] = covariance\n",
    "    return covarianceMatrix\n",
    "\n",
    "def pca(rgbImage):\n",
    "    covarianceMatrix = rgbImageCovarianceMatrix(rgbImage)\n",
    "    return np.linalg.svd(covarianceMatrix)\n",
    "\n",
    "def pcaTransform(rgbImage):\n",
    "    u,s,v = pca(rgbImage)\n",
    "    imageVector = flattenImage(rgbImage)\n",
    "    transposedVector = imageVector.dot(reorderMatrix(u))\n",
    "    return transposedVector.reshape(rgbImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_image = pcaTransform(images[0])\n",
    "\n",
    "_, ax = plt.subplots(1,4,figsize=(14,14))\n",
    "ax[0].imshow(images[0])\n",
    "ax[1].imshow(normalize_image(pca_image)[:,:,0])\n",
    "ax[2].imshow(normalize_image(pca_image)[:,:,1])\n",
    "ax[3].imshow(normalize_image(pca_image)[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_images = np.array([pcaTransform(image) for image in images])\n",
    "pca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = get_features_for(pca_images)\n",
    "pca_pixel_features = pca_features.reshape(120*75*75, 108)\n",
    "pca_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train, pca_X_test, pca_y_train, pca_y_test = train_test_split(pca_pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(pca_X_train, pca_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clf, pca_X_test, pca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = images[0].reshape(75*75,3)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pca = pca.transform(X).reshape(75,75,3)\n",
    "\n",
    "_, ax = plt.subplots(1,4,figsize=(14,14))\n",
    "ax[0].imshow(images[0][:,:,::-1])\n",
    "ax[1].imshow(normalize_image(im_pca)[:,:,0], cmap='gray')\n",
    "ax[2].imshow(normalize_image(im_pca)[:,:,1], cmap='gray')\n",
    "ax[3].imshow(normalize_image(im_pca)[:,:,2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(image):\n",
    "    X = image.reshape(image.shape[0]*image.shape[1], image.shape[2])\n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    return pca.transform(X).reshape(image.shape)\n",
    "\n",
    "ac_pca_images = np.array([pca_transform(image) for image in ac_dataset[0].images])\n",
    "ac_pca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_pca_features = get_features_for(ac_pca_images[:120])\n",
    "ac_pca_pixel_features = ac_pca_features.reshape(120*75*75, 108)\n",
    "ac_pca_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_dataset[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(normalize_image(ac_pca_images[i]))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_pred = clf.predict(ac_pca_pixel_features)\n",
    "prediction_images = im_pred.reshape(120, 75, 75)\n",
    "\n",
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(prediction_images[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0]\n",
    "mean_per_channel = np.mean(image, axis = (0,1))    \n",
    "mean_per_channel = np.ones((75,75,3)) * mean_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_substracted_image = images[0] - mean_per_channel\n",
    "mean_substracted_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_per_channel = np.std(image, axis = (0,1))\n",
    "std_per_channel = np.ones((75,75,3)) * std_per_channel\n",
    "std_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = mean_substracted_image / std_per_channel\n",
    "normalized_image.min(), normalized_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_normalize_image(image):\n",
    "    mean_per_channel = np.mean(image, axis = (0,1))    \n",
    "    mean_per_channel = np.ones((75,75,3)) * mean_per_channel\n",
    "    mean_substracted_image = images[0] - mean_per_channel\n",
    "    std_per_channel = np.std(image, axis = (0,1))\n",
    "    std_per_channel = np.ones((75,75,3)) * std_per_channel\n",
    "    return mean_substracted_image / std_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image = z_normalize_image(images[0])\n",
    "plt.imshow(normalize_image(z_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = image.sum(axis=2).reshape(image.shape[0], image.shape[1], 1).repeat(axis=2, repeats=3)\n",
    "sums.shape, sums[0:2,0:2,0], sums[0:2,0:2,1], sums[0:2,0:2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image = image / sums\n",
    "\n",
    "_, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(n_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image.min(), n_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_norm(image):\n",
    "    sums = image.sum(axis=2).reshape(image.shape[0], image.shape[1], 1).repeat(axis=2, repeats=3)\n",
    "    return image / sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(normalize_image(rgb_norm(images[i]))[:,:,::-1])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "positives = train[ac_dataset[0].labels == 1]\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(normalize_image(rgb_norm(positives[i]))[:,:,::-1])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(images[i][:,:,0], cmap=\"gray\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(train[i][:,:,0], cmap=\"gray\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Normalized RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_rgb_images = np.array([normalize_image(rgb_norm(image)) for image in images])\n",
    "norm_rgb_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 108)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_rgb_features = get_features_for(norm_rgb_images)\n",
    "norm_rgb_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000, 108)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_pixel_features = norm_rgb_features.reshape(120*75*75, 108)\n",
    "norm_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(norm_pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/.virtualenvs/cv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     91877\n",
      "         255       0.96      0.91      0.93     43123\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    135000\n",
      "   macro avg       0.96      0.95      0.95    135000\n",
      "weighted avg       0.96      0.96      0.96    135000\n",
      "\n",
      "accuracy=0.9589481481481481\n",
      "[[90206  1671]\n",
      " [ 3871 39252]]\n"
     ]
    }
   ],
   "source": [
    "predict(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(clf, image):\n",
    "    im_features = get_features_for([image])\n",
    "    im_features = im_features.reshape(75*75, 108)\n",
    "\n",
    "    im_pred = clf.predict(im_features)\n",
    "    return im_pred.reshape(75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[1]\n",
    "\n",
    "prediction_image = predict_image(clf, normalize_image(rgb_norm(img)))\n",
    "\n",
    "_, ax = plt.subplots(1,3, figsize=(10,10))\n",
    "ax[0].imshow(img[:,:,::-1])\n",
    "ax[1].imshow(normalize_image(rgb_norm(img))[:,:,::-1])\n",
    "ax[2].imshow(normalize_image(prediction_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = positives[0]\n",
    "\n",
    "prediction_image = predict_image(clf, normalize_image(rgb_norm(img)))\n",
    "\n",
    "_, ax = plt.subplots(1,3, figsize=(10,10))\n",
    "ax[0].imshow(img[:,:,::-1])\n",
    "ax[1].imshow(rgb_norm(img)[:,:,::-1])\n",
    "ax[2].imshow(normalize_image(prediction_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_images = np.array([cv.cvtColor(image, cv.COLOR_BGR2GRAY).reshape(image.shape[0], image.shape[1], 1) for image in images])\n",
    "gray_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f43da865828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gray_images[1][:,:, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 36)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_features = get_features_for(gray_images)\n",
    "gray_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000, 36)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_pixel_features = gray_features.reshape(120*75*75, gray_features.shape[-1])\n",
    "gray_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(gray_pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/.virtualenvs/cv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     92156\n",
      "         255       0.91      0.86      0.88     42844\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    135000\n",
      "   macro avg       0.92      0.91      0.92    135000\n",
      "weighted avg       0.93      0.93      0.93    135000\n",
      "\n",
      "accuracy=0.9285481481481481\n",
      "[[88613  3543]\n",
      " [ 6103 36741]]\n"
     ]
    }
   ],
   "source": [
    "predict(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_gray_images = np.array([cv.cvtColor(image.astype(np.float32), cv.COLOR_BGR2GRAY).reshape(image.shape[0], image.shape[1], 1) for image in train[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4391e177b8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ac_im_features = get_features_for([ac_gray_images[8]])\n",
    "ac_im_features = ac_im_features.reshape(75*75, 36)\n",
    "\n",
    "im_pred = clf.predict(ac_im_features)\n",
    "prediction_image = im_pred.reshape(75, 75)\n",
    "\n",
    "plt.imshow(prediction_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
